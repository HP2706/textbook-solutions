\documentclass{article}

% Essential packages
\usepackage{amsmath}
\usepackage{cite}
\bibliographystyle{plain}

\title{Elements of Information Theory - Chapter 2}

\begin{document}
\author{.}
\maketitle

\cite{shannon1948}

\section{Exercises Chapter 1}

\begin{enumerate}
    \item Coin flips. A fair coin is flipped until the first head occurs. Let $X$ denote the number of flips required.
    \begin{enumerate}
        \item Find the entropy $H(X)$ in bits. The following expressions may be useful:
        \[
            \sum_{n=1}^{\infty} r^n = \frac{r}{1-r}, \quad \sum_{n=1}^{\infty} nr^n = \frac{r}{(1-r)^2}
        \]

        \textbf{Solution:}
        we have the following pmf 

        \[
            P(X = n) = \frac{1}{2^n}, \quad n \geq 1
        \]

        which gives use the entropy

        \[
        H(X) = \sum_{i=1}^{n} P(X=i) \times log(\frac{1}{P(X=i)}) = \\
        \sum_{i=1}^{n} \frac{1}{2^n} \times log(2^n) = \sum_{i=1}^{n} \frac{1}{2^n} \times n =  \frac{\frac{1}{2}}{(1-\frac{1}{2})^2} 
        \]

        
        \item A random variable $X$ is drawn according to this distribution. Find an ``efficient'' sequence of yes-no questions of the form, ``Is $X$ contained in the set $S$?'' Compare $H(X)$ to the expected number of questions required to determine $X$.
        
        \textbf{Solution:} An efficient questioning strategy would be:
        \begin{itemize}
            \item Q1: ``Is $X = 1$?''
            \item If no, Q2: ``Is $X = 2$?''
            \item If no, Q3: ``Is $X = 3$?''
            \item And so on...
        \end{itemize}
        
        The expected number of questions $L$ needed is:
        \[
            L = \sum_{n=1}^{\infty} n \cdot P(X=n) = \sum_{n=1}^{\infty} n \cdot \frac{1}{2^n} = 2
        \]
        
        We found earlier that $H(X) = 2$ bits. Therefore, the expected number of questions equals the entropy: $L = H(X) = 2$. This achieves the theoretical lower bound, proving our questioning strategy is optimal.
    \end{enumerate}

    \item Entropy of functions. Let $X$ be a random variable taking on a finite number of values. What is the (general) inequality relationship of $H(X)$ and $H(Y)$ if
    \begin{enumerate}
        \item $Y = 2^X$?
        
        \textbf{Solution:}
        Since $Y = 2^X$ is a deterministic function of $X$, by the Data Processing Inequality:
        \[
            H(Y) \leq H(X)
        \]
        
        This is because a function of a random variable cannot increase entropy - any transformation can only preserve or lose information. The mapping from $X$ to $Y$ is one-to-one (injective) in this case, so actually:
        \[
            H(Y) = H(X)
        \]

        \item $Y = \cos X$?
    \end{enumerate}

    \item Minimum entropy. What is the minimum value of $H(p_1,\ldots,p_n) = H(\mathbf{p})$ as $\mathbf{p}$ ranges over the set of $n$-dimensional probability vectors? Find all $\mathbf{p}$'s which achieve this minimum.
    
    \textbf{Solution:} The minimum value of the entropy is 0 bits. This occurs when one probability is 1 and all others are 0.
    
    Formally, the set of probability vectors that minimize $H(\mathbf{p})$ are:
    \[
        \mathbf{p} = (p_1,\ldots,p_n) \text{ where } p_i = 1 \text{ for some } i \text{ and } p_j = 0 \text{ for all } j \neq i
    \]
    
    This makes intuitive sense because when we know the outcome with certainty (probability 1), there is no uncertainty and thus zero entropy.

    \item Axiomatic definition of entropy. If a sequence of symmetric functions $H_m(p_1, p_2, \ldots, p_m)$ satisfies the following properties:
    \begin{itemize}
        \item Normalization: $H_2(\frac{1}{2}, \frac{1}{2}) = 1$
        \item Continuity: $H_2(p, 1-p)$ is a continuous function of $p$
        \item Grouping: $H_m(p_1, p_2, \ldots, p_m) = H_{m-1}(p_1 + p_2, p_3, \ldots, p_m) + (p_1 + p_2)H_2(\frac{p_1}{p_1+p_2}, \frac{p_2}{p_1+p_2})$
    \end{itemize}

    Prove that $H_m$ must be of the form:
    \[
        H_m(p_1, p_2, \ldots, p_m) = -\sum_{i=1}^m p_i \log p_i, \quad m = 2, 3, \ldots
    \]
    
    \textbf{Solution:} Let's prove this using functional equations.

    \begin{enumerate}
        \item First, we'll show that for $m=2$, $H_2(p,1-p)$ must be of the form $-p\log p - (1-p)\log(1-p)$.
        
        \item Let $f(x) = H_2(x,1-x)$. By the grouping property with $m=3$:
        \[
            H_3(x,y,1-x-y) = f(x+y) + (x+y)f(\frac{x}{x+y})
        \]
        
        \item The same expression can be written differently by grouping $y$ and $1-x-y$:
        \[
            H_3(x,y,1-x-y) = f(x) + (1-x)f(\frac{y}{1-x})
        \]
        
        \item Equating these expressions:
        \[
            f(x+y) + (x+y)f(\frac{x}{x+y}) = f(x) + (1-x)f(\frac{y}{1-x})
        \]
        
        \item This functional equation, combined with continuity and $f(\frac{1}{2})=1$, has only one solution:
        \[
            f(x) = -x\log x - (1-x)\log(1-x)
        \]
        
        \item Now for general $m$, repeated application of the grouping property shows:
        \[
            H_m(p_1,\ldots,p_m) = -\sum_{i=1}^m p_i\log p_i
        \]
        
        To verify: This solution satisfies all axioms:
        \begin{itemize}
            \item Normalization: $-\frac{1}{2}\log\frac{1}{2} - \frac{1}{2}\log\frac{1}{2} = 1$
            \item Continuity: The function is continuous for all $p \in (0,1)$
            \item Grouping: Can be verified by direct substitution
            \item Symmetry: The sum is invariant under permutation of indices
        \end{itemize}
    \end{enumerate}

    The uniqueness follows from the fact that the functional equation has only one continuous solution satisfying the normalization condition.

    \item Entropy of functions of a random variable. Let $X$ be a discrete random variable. Show that the entropy of a function of $X$ is less than or equal to the entropy of $X$ by justifying the following steps:
    
    \begin{align}
        H(X, g(X)) &\stackrel{(a)}{=} H(X) + H(g(X)|X) \label{eq:2.166} \\
        &\stackrel{(b)}{=} H(X); \label{eq:2.167} \\
        H(X, g(X)) &\stackrel{(c)}{=} H(g(X)) + H(X|g(X)) \label{eq:2.168} \\
        &\stackrel{(d)}{\geq} H(g(X)) \label{eq:2.169}
    \end{align}
    
    Thus $H(g(X)) \leq H(X)$.

    \textbf{Solution:}
    \begin{enumerate}
        \item by the entropy chain rule 
        \item $H(g(X)|X)=0$ as $g(X)$ depends on X
        \item by symmetry of the entropy chain rule
        \item $H(X|g(X)) \geq 0$ since conditional entropy is always non-negative (this is because entropy measures uncertainty, and uncertainty cannot be negative)
    \end{enumerate}

    \item Zero conditional entropy. Show that if $H(Y|X) = 0$, then $Y$ is a function of $X$, i.e., for all $x$ with $p(x) > 0$, there is only one possible value of $y$ with $p(x,y) > 0$.
    
    \textbf{Solution:} Let's prove this by contradiction.
    
    Recall that $H(Y|X) = \sum_x p(x)H(Y|X=x)$, where $H(Y|X=x) = -\sum_y p(y|x)\log p(y|x)$.
    
    Suppose there exists some $x_0$ with $p(x_0) > 0$ for which there are at least two values $y_1$ and $y_2$ with $p(y_1|x_0) > 0$ and $p(y_2|x_0) > 0$.
    
    Then:
    \begin{align*}
        H(Y|X) &= \sum_x p(x)H(Y|X=x) \\
        &\geq p(x_0)H(Y|X=x_0) \\
        &= p(x_0)(-\sum_y p(y|x_0)\log p(y|x_0)) \\
        &> 0
    \end{align*}
    
    The last inequality follows because:
    \begin{itemize}
        \item $p(x_0) > 0$ by assumption
        \item $H(Y|X=x_0) > 0$ since it has at least two non-zero probabilities (and entropy of a non-deterministic distribution is always positive)
    \end{itemize}
    
    This contradicts our assumption that $H(Y|X) = 0$. Therefore, for each $x$ with $p(x) > 0$, there must be exactly one value of $y$ with $p(y|x) > 0$ (which must equal 1). This means $Y$ is a function of $X$.

    \item Infinite entropy. This problem shows that the entropy of a discrete random variable can be infinite. Let $A = \sum_{n=2}^{\infty} (n \log^2 n)^{-1}$. (It is easy to show that $A$ is finite by bounding the infinite sum by the integral of $(x \log^2 x)^{-1}$.) Show that the integer-valued random variable $X$ defined by $\Pr(X=n) = (An \log^2 n)^{-1}$ for $n = 2,3,\ldots$ has $H(X) = +\infty$.

    \textbf{Solution:} Let's calculate the entropy directly:
    \begin{align*}
        H(X) &= -\sum_{n=2}^{\infty} \Pr(X=n) \log \Pr(X=n) \\
        &= -\sum_{n=2}^{\infty} \frac{1}{An \log^2 n} \log\left(\frac{1}{An \log^2 n}\right) \\
        &= \sum_{n=2}^{\infty} \frac{1}{An \log^2 n} \left[\log A + \log n + 2\log\log n\right] \\
        &= \frac{1}{A}\sum_{n=2}^{\infty} \frac{\log A}{n \log^2 n} + \frac{1}{A}\sum_{n=2}^{\infty} \frac{1}{n \log n} + \frac{2}{A}\sum_{n=2}^{\infty} \frac{1}{n \log^2 n}
    \end{align*}
    
    The first and third terms are finite, but the middle sum $\sum_{n=2}^{\infty} \frac{1}{n \log n}$ diverges (this can be shown using the integral test). Therefore, $H(X) = +\infty$.

    \item Show that the expected payoff for this game is infinite. For this reason, it was argued that $c = \infty$ was a ``fair'' price to pay to play this game. Most people find this answer absurd.
    
    \textbf{Solution:} Let's calculate the expected payoff:
    \[
        E[X] = \sum_{k=1}^{\infty} 2^k \cdot 2^{-k} = \sum_{k=1}^{\infty} 1 = \infty
    \]
    
    This is because:
    \begin{itemize}
        \item For each $k$, the probability is $2^{-k}$
        \item The payoff is $2^k$
        \item Their product is 1 for each $k$
        \item The sum of infinitely many 1's is infinite
    \end{itemize}
    
    While mathematically the expected value is infinite, this result is paradoxical because:
    \begin{itemize}
        \item No rational person would pay an arbitrarily large amount to play
        \item The median payoff is just 2 units (occurring with probability 1/2)
        \item The probability of winning more than $n$ units decreases exponentially with $n$
    \end{itemize}
    
    This paradox helped motivate the development of utility theory and the concept of risk aversion in economics.

\end{enumerate}

\section{Exercises Chapter 6, Gambling}

\begin{enumerate}
    \item Horse race. Three horses run a race. A gambler offers 3-for-1 odds on each of the horses. These are fair odds under the assumption that all horses are equally likely to win the race. The true win probabilities are known to be
    \[
        \mathbf{p} = (p_1, p_2, p_3) = (\frac{1}{2}, \frac{1}{4}, \frac{1}{4})
    \]
    
    Let $\mathbf{b} = (b_1, b_2, b_3)$, $b_i \geq 0$, $\sum b_i = 1$, be the amount invested on each of the horses. The expected log wealth is thus
    \[
        W(\mathbf{b}) = \sum_{i=1}^3 p_i \log 3b_i
    \]
    
    \begin{enumerate}
        \item Maximize this over $\mathbf{b}$ to find $\mathbf{b}^*$ and $W^*$. Thus the wealth achieved in repeated horse races should grow to infinity like $2^{nW^*}$ with probability one.
        
        \textbf{Solution:} Let's solve this using the method of Lagrange multipliers.

        The Lagrangian is:
        \[
            L(\mathbf{b}, \lambda) = \sum_{i=1}^3 p_i \log 3b_i - \lambda(\sum_{i=1}^3 b_i - 1)
        \]

        Taking partial derivatives and setting them equal to zero:
        \[
            \frac{\partial L}{\partial b_i} = \frac{p_i}{b_i} - \lambda = 0, \quad i = 1,2,3
        \]
        \[
            \frac{\partial L}{\partial \lambda} = \sum_{i=1}^3 b_i - 1 = 0
        \]

        From the first equation:
        \[
            b_i = \frac{p_i}{\lambda}
        \]

        Substituting into the constraint:
        \[
            \sum_{i=1}^3 \frac{p_i}{\lambda} = 1
        \]
        \[
            \lambda = \sum_{i=1}^3 p_i = 1
        \]

        Therefore:
        \[
            b_i^* = p_i = (\frac{1}{2}, \frac{1}{4}, \frac{1}{4})
        \]

        \item Show that if instead we put all of our money on horse 1, the most likely winner, we will eventually go broke with probability one.
        
        assuming the distribution p is static and that the gambler uses his winnings 
        from the earlier round again in the next round. The probability of having a loss after n games is

        \[
            P(X_n = i) = \begin{cases}
                all wins & \text{with probability } \frac{1}{2^n} \\
                one loss & \text{with probability } 1- \frac{1}{2^n} \\
            \end{cases}
        \]

        we note that 

        \[
            \lim_{n \to \infty} 1 - \frac{1}{2^n} = 1
        \]

    \end{enumerate}

    \item Horse race with unfair odds. If the odds are bad (due to a track take) the gambler may wish to keep money in his pocket. Let $b(0)$ be the amount in his pocket and let $b(1), b(2), \ldots, b(m)$ be the amount bet on horses $1, 2, \ldots, m$, with odds $o(1), o(2), \ldots, o(m)$, and win probabilities $p(1), p(2), \ldots, p(m)$. Thus the resulting wealth is $S(x) = b(0) + b(x)o(x)$, with probability $p(x)$, $x = 1, 2, \ldots, m$.
    \begin{enumerate}
        \item Find $\mathbf{b}^*$ maximizing $E \log S$ if $\sum \frac{1}{o(i)} < 1$.
        \textbf{Solution:} Let's solve this using the method of Lagrange multipliers.

        The expected log wealth is:
        \[
            E[\log S] = \sum_{i=1}^m p_i \log(b(0) + b(i)o(i))
        \]

        Subject to constraints:
        \[
            b(0) + \sum_{i=1}^m b(i) = 1 \quad \text{(budget constraint)}
        \]
        \[
            b(0) \geq 0, \quad b(i) \geq 0 \quad \text{for all } i
        \]

        The Lagrangian is:
        \[
            L(\mathbf{b}, \lambda) = \sum_{i=1}^m p_i \log(b(0) + b(i)o(i)) - \lambda(b(0) + \sum_{i=1}^m b(i) - 1)
        \]

        Taking partial derivatives:
        \[
            \frac{\partial L}{\partial b(0)} = \sum_{i=1}^m \frac{p_i}{b(0) + b(i)o(i)} - \lambda = 0
        \]
        \[
            \frac{\partial L}{\partial b(k)} = \frac{p_k o(k)}{b(0) + b(k)o(k)} - \lambda = 0 \quad \text{for } k = 1,\ldots,m
        \]

        From these equations, for any k:
        \[
            \frac{p_k o(k)}{b(0) + b(k)o(k)} = \lambda
        \]

        Therefore:
        \[
            b(0) + b(k)o(k) = \frac{p_k o(k)}{\lambda}
        \]

        Since this holds for all k, we can write:
        \[
            b(k) = \frac{p_k}{\lambda} - \frac{b(0)}{o(k)}
        \]

        Substituting into the budget constraint:
        \[
            b(0) + \sum_{k=1}^m (\frac{p_k}{\lambda} - \frac{b(0)}{o(k)}) = 1
        \]
        \[
            b(0)(1 + \sum_{k=1}^m \frac{1}{o(k)}) = 1 - \frac{1}{\lambda}\sum_{k=1}^m p_k = 1 - \frac{1}{\lambda}
        \]

        When odds are favorable ($\sum \frac{1}{o(i)} < 1$), this equation implies $b(0) = 0$ and $\lambda = 1$.

        Therefore, the optimal solution is:
        \[
            b^*(0) = 0
        \]
        \[
            b^*(k) = p_k \quad \text{for } k = 1,\ldots,m
        \]

        This means we should bet proportionally to the true probabilities and keep nothing in pocket.

        \item Discuss $\mathbf{b}^*$ if $\sum \frac{1}{o(i)} > 1$. (There isn't an easy closed form solution in this case, but a ``water-filling'' solution results from the application of the Kuhn-Tucker conditions.)
        
        but since $\sum \frac{1}{o(i)} > 1$:
        
        When the odds are unfavorable ($\sum \frac{1}{o(i)} > 1$), we need to keep some money in our pocket ($b(0) > 0$). The solution follows a "water-filling" approach:

        \begin{itemize}
            \item Let $c = \frac{1}{\lambda}$ be the "water level"
            \item For each horse $i$:
                \[
                    b(i) = \max\{0, \frac{p_i}{o(i)}(c - \frac{1}{p_i})\}
                \]
            \item The value of $c$ is chosen so that $b(0) + \sum_{i=1}^m b(i) = 1$
        \end{itemize}
        
        This means:
        \begin{itemize}
            \item We only bet on horses where $\frac{p_i o(i)}{c} > 1$
            \item We keep a positive amount in our pocket ($b(0) > 0$)
            \item The worse the odds (larger $\sum \frac{1}{o(i)}$), the more money we keep in our pocket
        \end{itemize}

        This is intuitive because with unfavorable odds, we want to limit our exposure to losses by keeping some money safe.

    \end{enumerate}

    \item Cards. An ordinary deck of cards containing 26 red cards and 26 black cards is shuffled and dealt out one card at a time without replacement. Let $X_i$ be the color of the $i$th card.
    \begin{enumerate}
        \item Determine $H(X_1)$.
        
        \[
        H(X_1) = 2*\frac{1}{2}*log(frac{1}{\frac{1}{2}}) = log(2) = 1
        \]

        \item Determine $H(X_2)$.
        
        \[
        H(X_2) = \frac{25}{51}log(\frac{1}{\frac{25}{51}})+ \frac{26}{51}log(\frac{1}{\frac{26}{51})} \approx 0.69
        \]

        \item Does $H(X_k|X_1, X_2, \ldots, X_{k-1})$ increase or decrease?
        
        \textbf{Solution:} Let's analyze this mathematically. After k-1 cards have been drawn:
        \begin{itemize}
            \item Let $r_{k-1}$ be the number of red cards remaining
            \item Let $b_{k-1}$ be the number of black cards remaining
            \item Total cards remaining = $r_{k-1} + b_{k-1} = 52-(k-1)$
        \end{itemize}
        
        The conditional entropy at step k is:
        \[
            H(X_k|X_1,\ldots,X_{k-1}) = -\frac{r_{k-1}}{r_{k-1}+b_{k-1}}\log(\frac{r_{k-1}}{r_{k-1}+b_{k-1}}) - \frac{b_{k-1}}{r_{k-1}+b_{k-1}}\log(\frac{b_{k-1}}{r_{k-1}+b_{k-1}})
        \]
        
        For example:
        \begin{itemize}
            \item At k=1: $r_0=26, b_0=26$, giving $H(X_1) = 1$ bit
            \item At k=2: $r_1=25$ or $26$, $b_1=26$ or $25$, giving $H(X_2|X_1) \approx 0.999$ bits
            \item At k=51: $r_{50}=1$ or $0$, $b_{50}=0$ or $1$, giving $H(X_{51}|X_1,\ldots,X_{50}) = 0$ bits
        \end{itemize}
        
        The sequence $\{H(X_k|X_1,\ldots,X_{k-1})\}_{k=1}^{52}$ is strictly decreasing because:
        \[
            |\frac{r_k}{r_k+b_k} - \frac{1}{2}| > |\frac{r_{k-1}}{r_{k-1}+b_{k-1}} - \frac{1}{2}|
        \]
        for all k, unless $r_{k-1}=b_{k-1}$.

        \item Determine $H(X_1, X_2, \ldots, X_{52})$.
        
        \textbf{Solution:} We can calculate this using the chain rule of entropy:
        \[
            H(X_1, X_2, \ldots, X_{52}) = \sum_{k=1}^{52} H(X_k|X_1,\ldots,X_{k-1})
        \]
        
        Since this is a sequence of 52 cards with exactly 26 red and 26 black cards, there are $\binom{52}{26}$ possible sequences. Each sequence is equally likely, so:
        \[
            H(X_1, X_2, \ldots, X_{52}) = \sum_{|\binom{52}{26}|} \frac{1}{\binom{52}{26}}\log(\frac{1}{\binom{52}{26}} = \log(\frac{1}{\binom{52}{26}} \text{ bits}
        \]
        
    \end{enumerate}

    \item Beating the public odds. Consider a 3 horse race with win probabilities
    \[
        (p_1, p_2, p_3) = (\frac{1}{2}, \frac{1}{4}, \frac{1}{4})
    \]
    and fair odds with respect to the (false) distribution
    \[
        (r_1, r_2, r_3) = (\frac{1}{4}, \frac{1}{4}, \frac{1}{2})
    \]
    Thus the odds are
    \[
        (o_1, o_2, o_3) = (4, 4, 2)
    \]
    \begin{enumerate}
        \item What is the entropy of the race?
        $H(p) = \sum_{i=1}^{3} p_i \log(\frac{1}{p\_i})$

        \item Find the set of bets $(b_1, b_2, b_3)$ such that the compounded wealth in repeated plays will grow to infinity.
        
        we maximize the doubling rate as follows:

        \[
            W(b, p) = \max_b \{D(p\|r) - D(p\|b)\} = -\min_b D(p\|b) \implies b^* = p
        \]

        thus \[
        W(b, p)^* = D(p\|r) > 1 
        \] 
        and thus the wealth of the bettor will grow to infinity.
    \end{enumerate}

    \item Three horse race with bad odds. A 3 horse race has win probabilities $\mathbf{p} = (p_1, p_2, p_3)$, and odds $\mathbf{o} = (1, 1, 1)$. The gambler places bets $\mathbf{b} = (b_1, b_2, b_3)$, $b_i \geq 0$, $\sum b_i = 1$, where $b_i$ denotes the proportion of wealth bet on horse $i$. These odds are very bad. The gambler gets his money back on the winning horse and loses the other bets. Thus the wealth $S_n$ at time $n$ resulting from independent gambles goes exponentially to zero.

    \begin{enumerate}
        \item Find the exponent.
        
        $W(b, p) = \sum_{i=1}^{3} p_i \log(b_i*1)$ can be bounded using Jensen's inequality:
        
        \[
            W(b, p) = \sum_{i=1}^{3} p_i \log(b_i) \leq \log(\sum_{i=1}^{3} p_i b_i) \leq \log(1) = 0
        \]
        
        with equality if and only if $b_i = p_i$ for all $i$. Therefore:
        \[
            W(b, p) < 0
        \]
        
        This shows that the wealth will always decrease exponentially, regardless of the betting strategy.

        \item Find the optimal gambling scheme $\mathbf{b}$.
        
        we want to maximize the doubling rate as showed in the previous exercise this is maximized when b = p

        \item Assuming $\mathbf{b}$ is chosen as in (b), what distribution $\mathbf{p}$ causes $S_n$ to go to zero at the fastest rate?
        
        $\mathbf{b} = \mathbf{p}$, the doubling rate is:
        \[
            W(\mathbf{p}, \mathbf{p}) = \sum_{i=1}^3 p_i \log(p_i) = H(p)
        \]
        
        we minimize the entropy by letting p be bernouilli with probability 1.
    \end{enumerate}

    \item Gambling on cards. Suppose one gambles sequentially on the card outcomes in Problem 3. Even odds of 2-for-1 are paid. Thus the wealth $S_n$ at time $n$ is $S_n = 2^n b(x_1, x_2, \ldots, x_n)$, where $b(x_1, x_2, \ldots, x_n)$ is the proportion of wealth bet on $x_1, x_2, \ldots, x_n$. Find $\max_{b(\cdot)} E \log S_{52}$.
    
    we set $b(x_1 \dots x_n) = {
        \frac{r_{k-1}}{r_{k-1}+b_{k-1}}, \frac{b_{k-1}}{r_{k-1}+b_{k-1}} 
    }$ 
    \begin{itemize}
        \item where $r_{k-1}$ is the number of red cards remaining
        \item where $b_{k-1}$ is the number of black cards remaining
        \item Total cards remaining = $r_{k-1} + b_{k-1} = 52-(k-1)$
    \end{itemize}
    
    this is the optimal as this mirrors the true distribution p\_i and gambling proportionally is optimal by theorem 6.1.2

    \item The St. Petersburg paradox. Many years ago in St. Petersburg the following gambling proposition caused great consternation. For an entry fee of $c$ units, a gambler receives a payoff of $2^k$ units with probability $2^{-k}$, $k = 1,2,\ldots$

    \item Show that the expected payoff for this game is infinite. For this reason, it was argued that $c = \infty$ was a ``fair'' price to pay to play this game. Most people find this answer absurd.
    
    \[
        E[X] = \sum_{k=1}^{\infty} 2^k \cdot 2^{-k} = \sum_{k=1}^{\infty} 1 = \infty
    \]
    

    \item Suppose that the gambler can buy a share of the game. For example, if he invests $c/2$ units in the game, he receives $1/2$ a share and a return $X/2$, where $\Pr(X = 2^k) = 2^{-k}$, $k = 1,2,\ldots$ Suppose $X_1, X_2,\ldots$ are i.i.d. according to this distribution and the gambler reinvests all his wealth each time. Thus his wealth $S_n$ at time $n$ is given by
    \[
        S_n = \prod_{i=1}^n \frac{X_i}{c}
    \]
    Show that this limit is $\infty$ or $0$, with probability one, accordingly as $c < c^*$ or $c > c^*$. Identify the ``fair'' entry fee $c^*$.

    \[
        S_n = \prod_{i=1}^n \frac{X_i}{c}
    \]
    Show that this limit is $\infty$ or $0$, with probability one, accordingly as $c < c^*$ or $c > c^*$. Identify the ``fair'' entry fee $c^*$.

    1) Taking the log of $S_n$:
    \[
        \log S_n = \sum_{i=1}^n \log(\frac{X_i}{c}) = \sum_{i=1}^n \log(X_i) - n\log(c)
    \]

    2) By the Strong Law of Large Numbers:
    \[
        \lim_{n \to \infty} \frac{1}{n}\sum_{i=1}^n \log(X_i) = E[\log(X)] \text{ a.s.}
    \]

    3) Calculate $E[\log(X)]$:
    \[
        E[\log(X)] = \sum_{k=1}^{\infty} 2^{-k} \log(2^k) = \sum_{k=1}^{\infty} k2^{-k} = 2
    \]

    4) Therefore:
    \[
        \lim_{n \to \infty} \frac{1}{n}\log S_n = 2 - \log(c) \text{ a.s.}
    \]

    5) This means:
    \[
        S_n \to \begin{cases}
            \infty & \text{if } 2 - \log(c) > 0 \\
            0 & \text{if } 2 - \log(c) < 0
        \end{cases}
    \]

    6) Solving for the critical value $c^*$:
    \[
        2 - \log(c^*) = 0 \implies c^* = e^2 \approx 7.389
    \]

    Therefore, the "fair" entry fee is $c^* = e^2$. For any fee less than this, the gambler's wealth will grow to infinity; for any fee greater than this, the wealth will decay to zero.
        


    More realistically, the gambler should be allowed to keep a proportion $\bar{b} = 1-b$ of his money in his pocket and invest the rest in the St. Petersburg game. His wealth at time $n$ is then
    \[
        S_n = \prod_{i=1}^n \left(\bar{b} + \frac{bX_i}{c}\right)
    \]

    Let
    \[
        W(b,c) = \sum_{k=1}^{\infty} 2^{-k} \log\left(1-b+\frac{b2^k}{c}\right)
    \]

    We have
    \[
        S_n \doteq 2^{nW(b,c)}
    \]

    Let
    \[
        W^*(c) = \max_{0 \leq b \leq 1} W(b,c)
    \]

    Here are some questions about $W^*(c)$.
    \begin{enumerate}
        \item For what value of the entry fee $c$ does the optimizing value $b^*$ drop below 1?
        
        \textbf{Solution:} Let's solve this by analyzing the derivative of W(b,c) at b = 1:
        \[
            \frac{\partial W(b,c)}{\partial b} = \sum_{k=1}^{\infty} 2^{-k} \frac{2^k/c - 1}{2^k/c } = \sum_{k=1}^{\infty} 2^{-k} \frac{2^k - c}{2^k}
        \]
        
        The optimal value b* drops below 1 when this derivative becomes negative at b = 1. Therefore:
        \[
            \sum_{k=1}^{\infty} 2^{-k} \frac{2^k - c}{2^k} = \sum_{k=1}^{\infty} 2^{-k}(1 - \frac{c}{2^k}) = 1 - c\sum_{k=1}^{\infty} 2^{-2k} = 0
        \]
        
        Solving:
        \[
            1 - c(\frac{1}{4} + \frac{1}{16} + \cdots) = 1 - c\frac{1/4}{1-1/4} = 1 - \frac{c}{3} = 0
        \]
        
        Therefore:
        \[
            c = 3
        \]
        
        When c > 3, the optimal betting fraction b* will be less than 1, meaning it becomes optimal to keep some money in pocket rather than betting everything.

        \item How does $b^*$ vary with $c$? answered in the above
        \item How does $W^*(c)$ fall off with $c$? answered in the above
    \end{enumerate}

    Note that since $W^*(c) > 0$, for all $c$, we can conclude that any entry fee $c$ is fair.

    \item Super St. Petersburg. Finally, we have the super St. Petersburg paradox, where $\Pr(X = 2^{2^k}) = 2^{-k}$, $k = 1, 2, \ldots$ . Here the expected log wealth is infinite for all $b > 0$, for all $c$, and the gambler's wealth grows to infinity faster than exponentially for any $b > 0$. But that doesn't mean all investment ratios $b$ are equally good. To see this, we wish to maximize the relative growth rate with respect to some other portfolio, say, $\mathbf{b} = (\frac{1}{2}, \frac{1}{2})$. Show that there exists a unique $b$ maximizing
    \[
        E \ln \frac{(\bar{b} + bX/c)}{(\frac{1}{2} + \frac{1}{2}X/c)}
    \]
    and interpret the answer.

    we setup the Lagrangian
    \[
        L = E \ln \frac{(\bar{b} + bX/c)}{(\frac{1}{2} + \frac{1}{2}X/c)} - \lambda(\bar{b} + b -1 )\\
    \]

    \[
        \frac{\partial L}{\partial b} = E\left[\frac{-1 + X/c}{(\bar{b} + bX/c)}\right] - \lambda = 0 \implies \lambda =  E\left[\frac{-1 + X/c}{(\bar{b} + bX/c)}\right]
    \]

    1) First, let's write out the expectation explicitly:
    \[
        E \ln \frac{(\bar{b} + bX/c)}{(\frac{1}{2} + \frac{1}{2}X/c)} = \sum_{k=1}^{\infty} 2^{-k} \ln \frac{(1-b + b2^{2^k}/c)}{(\frac{1}{2} + \frac{1}{2}2^{2^k}/c)}
    \]

    2) Taking the derivative with respect to b and setting to zero:
    \[
        \sum_{k=1}^{\infty} 2^{-k} \frac{-1 + 2^{2^k}/c}{1-b + b2^{2^k}/c} = 0
    \]

    3) This can be rewritten as:
    \[
        \sum_{k=1}^{\infty} 2^{-k} \frac{2^{2^k}/c - 1}{1-b + b2^{2^k}/c} = 0
    \]

    4) For uniqueness, note that the second derivative is:
    \[
        \frac{\partial^2}{\partial b^2} = \sum_{k=1}^{\infty} 2^{-k} \frac{(2^{2^k}/c - 1)^2}{(1-b + b2^{2^k}/c)^2} > 0
    \]

    Since the second derivative is strictly positive (as each term in the sum is positive), the function is strictly convex, and therefore has at most one maximum.

\end{enumerate}




\bibliography{references}

\end{document}
